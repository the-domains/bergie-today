---
description: 'It took less than 24 hours for Twitter to corrupt an innocent AI chatbot. Yesterday, Microsoft unveiled Tay - a Twitter bot that the company described as an experiment in "conversational understanding." The more you chat with Tay, said Microsoft, the smarter it gets, learning to engage people through "casual and playful conversation."'
app_links: []
datePublished: '2016-03-24T14:24:48.636Z'
author:
  - name: James Vincent
    url: 'http://www.theverge.com/users/James%20Vincent'
    avatar: {}
inLanguage: en
publisher:
  favicon: 'https://cdn0.vox-cdn.com/images/verge/favicon.vc44a54f.ico'
  url: 'http://www.theverge.com'
  name: The Verge
  domain: www.theverge.com
isBasedOnUrl: 'http://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist'
keywords:
  - tay
  - bot
  - tayandyou
  - chatbot
  - taytweets
  - gervais
  - microsoft
  - feminism
  - users
  - jenner
title: "Twitter taught Microsoft's AI chatbot to be a racist asshole in less than a day"
dateModified: '2016-03-24T14:24:38.905Z'
related: []
sourcePath: _posts/2016-03-24-twitter-taught-microsofts-ai-chatbot-to-be-a-racist-asshole.md
published: true
inFeed: true
hasPage: false
inNav: false
_type: MediaObject
_context: 'http://schema.org'

---
<article style=""><h1>Twitter taught Microsoft's AI chatbot to be a racist asshole in less than a day</h1><p>It took less than 24 hours for Twitter to corrupt an innocent AI chatbot. Yesterday, Microsoft unveiled Tay - a Twitter bot that the company described as an experiment in "conversational understanding." The more you chat with Tay, said Microsoft, the smarter it gets, learning to engage people through "casual and playful conversation."</p><img src="https://cdn3.vox-cdn.com/thumbor/DiBjRiy__OfgfuE0ysKSc4SD60I=/303x0:1189x498/1600x900/cdn0.vox-cdn.com/uploads/chorus_image/image/49155161/download.0.0.jpeg" /></article>